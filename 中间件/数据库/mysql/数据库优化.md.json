{"content":"# 数据库优化\n\n对于优化最重要的事是测量，如果优化的成本高于收益，就要停止优化。\n\n## 优化原因\n\n- 避免网站出现访问错误\n- 低效的查询导致数据库不稳定\n- 优化用户体验\n\n## 优化方面\n\n- 硬件\n- 系统配置\n- 数据库表结构\n- SQL与索引\n\n成本从下到上递增，效果从上到下递减\n\n## MYSQL优化\n\n### 监控\n\n#### 性能剖析 show profile(逐渐淘汰)\n\n一条SQL语句结束后\n\n使用show profile查询剖析工具，可以指定具体的type\n\n```sh\nshow profile cpu;\n```\n\nall：显示所有性能信息\n\nblock io：显示块io操作的次数\n\ncontext switches：显示上下文切换次数，被动和主动\n\ncpu：显示用户cpu时间、系统cpu时间\n\nIPC：显示发送和接受的消息数量\n\nmemory：内存\n\npage faults：显示页错误数量\n\nsource：显示源码中的函数名称与位置\n\nswaps：显示swap的次数\n\nshow status则可以查看相关计数器数据，计数器数据价值相较于profile低。\n\n#### 使用performance schema\n\n通过该数据库直接通过sql就能得到服务器相关的一些测量信息\n\n#### 使用show processlist查看连接的线程个数\n\n## 开启慢查询\n\n慢查询日志式开销最低，精度最高的测量查询时间的工具\n\n```shell\nset global slow_query_log=ON; #开启慢查询\nset global long_query_time=1.0; #设置记录时长为1秒\nset global log_queries_not_using_indexes = ON; #不适用索引\n```\n\n慢查询日志地址：\n\n地址存储在slow_query_log_file变量中\n\n## 慢查询日志存储格式\n\n```\n# Time: 2019-11-29T06:01:43.909217Z 执行时间\n# User@Host: root[root] @ localhost []  Id:     9 主机信息\n# Query_time: 0.104442 查询时间\n  Lock_time: 0.000153 锁定时间\n   Rows_sent: 1  发送行数\n   Rows_examined: 16249 锁扫描行数\nSET timestamp=1575007303; 执行时间戳\nselect count(*) from actor,payment; SQL\n```\n\n## 慢查询分析工具\n\n- mysqldumpslow\n\n```shell\nmysqldumpslow -t 10 日志地址 # 分析前10条记录\n```\n\n- pt-query-digest\n\n```shell\nwget percona.com/get/pt-query-digest # 下载\nchmod u+x pt-query-digest # 添加执行权限\n/pt-query-digest 慢查询日志地址 # 分析日志\n```\n\n## 问题定位\n\n- 次数多、时间长\n- IO大\n- 未命中索引\n\n## 查询执行计划\n\n```sql\nexplain sql\n```\n\n```text\nid: 1\n  select_type: SIMPLE # \n        table: staff\n   partitions: NULL\n         type: index\npossible_keys: NULL\n          key: idx_fk_store_id\n      key_len: 1\n          ref: NULL\n         rows: 2\n     filtered: 100.00\n        Extra: Using index\n```\n\n- id: SELECT 查询的标识符. 每个 SELECT 都会自动分配一个唯一的标识符.\n- **select_type**: SELECT 查询的类型.\n\n  - SIMPLE, 表示此查询不包含 UNION 查询或子查询\n  - PRIMARY, 表示此查询是最外层的查询\n  - UNION, 表示此查询是 UNION 的第二或随后的查询\n  - DEPENDENT UNION, UNION 中的第二个或后面的查询语句, 取决于外面的查询\n  - UNION RESULT, UNION 的结果\n  - SUBQUERY, 子查询中的第一个 SELECT\n  - DEPENDENT SUBQUERY: 子查询中的第一个 SELECT, 取决于外面的查询. 即子查询依赖于外层查询的结果.\n\n- table: 查询的是哪个表\n\n- partitions: 匹配的分区\n- type: join 类型 通常来说, 不同的 type 类型的性能关系:ALL < index < range ~ index_merge < ref < eq_ref < const < system\n- possible_keys: 此次查询中可能选用的索引\n- **key**: 此次查询中确切使用到的索引\n- key_len:表示查询优化器使用了索引的字节数. 这个字段可以评估组合索引是否完全被使用, 或只有最左部分字段被使用到\n- **rows**:估算 SQL 要查找到结果集需要扫描读取的数据行数，这个值非常直观显示 SQL 的效率好坏, 原则上 rows 越少越好\n- extra:EXplain 中的很多额外的信息会在 Extra 字段显示\n\n  - Using filesort:表示 MySQL 需额外的排序操作, 不能通过索引顺序达到排序效果，一般有 Using filesort, 都建议优化去掉, 因为这样的查询 CPU 资源消耗大\n  - Using index：\"覆盖索引扫描\", 表示查询在索引树中就可查找所需数据, 不用扫描表数据文件, 往往说明性能不错\n  - Using temporary：查询有使用临时表, 一般出现于排序, 分组和多表 join 的情况, 查询效率不高, 建议优化\n\n## 索引优化\n\n### 索引\n\n### 创建索引\n\nALTER TABLE用来创建普通索引、UNIQUE索引或PRIMARY KEY索引\n\n```sql\nALTER TABLE table_name ADD INDEX index_name (column_list)\n\nALTER TABLE table_name ADD UNIQUE (column_list)\n\nALTER TABLE table_name ADD PRIMARY KEY (column_list)\n```\n\nCREATE INDEX可对表增加普通索引或UNIQUE索引\n\n```sql\nCREATE INDEX index_name ON table_name (column_list)\n\nCREATE UNIQUE INDEX index_name ON table_name (column_list)\n```\n\n获取索引\n\n```sql\nshow keys  from table_name\n```\n\n### 何时使用索引\n\n- 主键列中创建索引\n- 多表连接时连接列创建索引\n- where子句查询的列\n- 需要经常GROUP BY和ORDER BY的列\n\n### 索引优化\n\n- 找出重复冗余索引\n- 索引不包含NULL\n- 短索引\n- 排序的索引问题\n- like语句前%不会使用索引\n- 列上运算问题\n- NOT IN会进行全表扫描\n\n## 数据库结构优化\n\n- 选择合适的数据类型\n- 范式化\n- 反范式化\n- 垂直拆分\n\n![2020310201242](/assets/2020310201242.jpg)\n\n使用垂直切分将按数据库中表的密集程度部署到不同的库中\n\n切分后部分表无法join，只能通过接口方式解决，提高了系统复杂度，存在分布式事务问题\n\n- 水平拆分\n\n![2020310201126](/assets/2020310201126.jpg)\n\n当一个表的数据不断增多时，水平拆分是必然的选择，它可以将数据分布到集群的不同节点上，从而缓存单个数据库的压力\n\n### 分库分表\n\n同上面的水平拆分，每张表或者每个库只存储一定量的数据，当需要进行数据读写时，根据唯一ID取模得到数据的位置\n\n**为什么分库分表能提高性能**\n\n将一张表的数据拆分成多个n张表进行存放，然后使用第三方中间件（MyCat或者Sharding-JDBC）可以并行查询\n\n**一些分库分表中间件**\n\ncobar，tddl，atlas，**sharing-jdbc**，**my-cat**\n\n**系统迁移到分库分表**\n\n如何将一个单裤单表的系统动态迁移到分库分表上去\n\n- 停机迁移\n\n禁止全部数据写入，编写一个程序，将单库单表的数据写到分库分表上\n\n![批注 2020-03-20 163424](/assets/批注%202020-03-20%20163424.png)\n\n- 双写迁移\n\n新系统部署后，每条数据都会在老库和新库写一遍\n后台开启一个数据库迁移工具，这个工具负责把老库的数据写到新库去\n写到新库的条件是，老库有的数据新库的没用或者是 老库的数据更新时间比新库的新\n工具会比较新库与老库的每一条数据，只有每条数据都一致，才算完成，否则继续新一轮迁移\n这样工具几轮操作过去后，新老库的数据就一致了\n\n![批注 2020-03-20 163921](/assets/批注%202020-03-20%20163921.png)\n\n**动态扩容缩容的分库分表方案**\n\n- 停机扩容\n\n同上，只不过上面那是从单个数据库到多个数据库，这次这个是多个数据库到多个数据库\n但是不推荐这种做法，原因是数据量很大，数据很难在短时间内转移完毕\n\n- 第一次分库分表，就一次性给他分个够\n\n32 个库，每个库 32 个表\n这里可以多个库都在同一台机器上，当不够用的时候，可以将这些库转移到新机器上\n这样，数据的逻辑位置没有发生改变，也避免扩容缩容带来的数据迁移问题\n\n**分库分表后的ID**\n\n- 使用一个系统来做自增ID的获取\n  - redis、数据库自带的自增\n  - 多个节点的ID获取无法并行\n- 不同的数据自增ID设置相同的步长不同的初始值，这样就能保证这些节点ID不会重复\n  - 但这种方式注定了数据库节点数量不能变化\n- uuid\n  - UUID组成部分:当前日期和时间+时钟序列+随机数+全局唯一的IEEE机器识别号\n  - 比较长，无法保证趋势递增，做索引时查询效率低\n- 系统时间\n  - 可以使用业务字段来拼接避免重复\n- 雪花算法\n  - 一个 64 位的 long 型的 id，1 个 bit 是不用的，用其中的 41 bit 作为毫秒数，用 10 bit 作为工作机器 id，12 bit 作为序列号\n  - 单个节点内无法并行\n  - 多个节点可以并行\n  - 可以支撑每秒几万的情况\n\n### 拆分策略\n\n使用水平拆分时，操作一条数据，要在哪张表找到它\n\n- 哈希取模\n- 范围，ID范围，时间范围\n- 映射表\n\n### 拆分后的问题\n\n- 事务\n  - 使用分布式事务\n- 连接\n  - 原来的连接需要分解成多个单表查询，在应用层进行连接\n- ID唯一性\n  - 全局唯一ID（GUID）\n  - 每个分片指定ID范围\n  - 分布式ID生成器，雪花算法\n\n## 数据访问优化\n\n### 减少请求的数据量\n\n- SELECT 只返回必要的列\n- 使用LIMIT只返回必要的行\n- 在内存缓存数据避免查询数据库\n\n### 减少扫描行数\n\n使用索引覆盖来覆盖查询\n\n## 查询方式优化\n\n### 分解大查询\n\n一个大查询如果一次性执行的话，可能一次锁住很多数据、占满整个事务日志、耗尽系统资源\n\n### 分解大连接查询\n\n将一个大连接查询分解成对每一个表进行一次单表查询，然后在应用程序中进行关联\n\n- 可以有效利用缓存\n- 减少锁竞争\n- 应用层拼接数据，数据库拆分更容易，从而做到高性能和可伸缩\n- 单表查询效率可能比连接高\n\n# 配置优化\n\n- 设置文件最大打开数\n- 设置最大连接数\n- 设置back_log\n\n  - 存放等待连接的堆栈大小\n\n- interactive_timeout\n- 缓冲区\n\n  - key_buffer_size\n  - query_cache_size\n  - record_buffer_size\n  - read_rnd_buffer_size\n  - sort_buffer_size\n  - join_buffer_size\n  - tmp_table_size\n  - table_cache\n  - max_heap_table_size\n  - thread_cache_size\n  - thread_concurrency\n  - wait_timeout\n\n- 关于InnoDB\n\n# 执行顺序\n\n![](https://images0.cnblogs.com/i/243280/201406/082230505368061.png)\n\n- FORM: 对FROM的左边的表和右边的表计算笛卡尔积。产生虚表VT1\n- ON: 对虚表VT1进行ON筛选，只有那些符合`<join-condition>`的行才会被记录在虚表VT2中。\n- JOIN： 如果指定了OUTER JOIN（比如left join、 right join），那么保留表中未匹配的行就会作为外部行添加到虚拟表VT2中，产生虚拟表VT3, rug from子句中包含两个以上的表的话，那么就会对上一个join连接产生的结果VT3和下一个表重复执行步骤1~3这三个步骤，一直到处理完所有的表为止。\n- WHERE： 对虚拟表VT3进行WHERE条件过滤。只有符合`<where-condition>`的记录才会被插入到虚拟表VT4中。\n- GROUP BY: 根据group by子句中的列，对VT4中的记录进行分组操作，产生VT5.\n- CUBE | ROLLUP: 对表VT5进行cube或者rollup操作，产生表VT6.\n- HAVING： 对虚拟表VT6应用having过滤，只有符合`<having-condition>`的记录才会被 插入到虚拟表VT7中。\n- SELECT： 执行select操作，选择指定的列，插入到虚拟表VT8中。\n- DISTINCT： 对VT8中的记录进行去重。产生虚拟表VT9.\n- ORDER BY: 将虚拟表VT9中的记录按照`<order_by_list>`进行排序操作，产生虚拟表VT10.\n- LIMIT：取出指定行的记录，产生虚拟表VT11, 并将结果返回。\n\n\n","commitList":[{"date":"2021-10-08T12:45:10+08:00","author":"cjiping","message":"doc开发期 构建期调整","hash":"704efe7455b7fb2fbd81ec60099191ff982e639a"},{"date":"2021-10-07T19:38:58+08:00","author":"My","message":"init","hash":"4e0456332231ba0523aa526415f9982377358870"}],"hasMoreCommit":false,"totalCommits":0}