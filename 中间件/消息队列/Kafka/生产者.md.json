{"content":"# 生产者\n\n![屏幕截图 2020-08-20 150154](/assets/屏幕截图%202020-08-20%20150154.png)\n\n发送消息：\n\n```java\nProperties props = new Properties();\n//kafka 集群，broker-list\nprops.put(\"bootstrap.servers\", \"172.24.211.140:9092\");\nprops.put(\"key.serializer\",\n        \"org.apache.kafka.common.serialization.StringSerializer\");\nprops.put(\"value.serializer\",\n        \"org.apache.kafka.common.serialization.StringSerializer\");\nProducer<String,  String> producer  =  new\n        KafkaProducer<>(props);\nfor (int i = 0; i < 10; i++) {\n    var record =\n            new ProducerRecord<>(\"test\", \"Precision Products\",\n                    \"France\");\n    producer.send(record, new Callback() {\n        @Override\n        public void onCompletion(RecordMetadata metadata, Exception exception) {\n            System.out.println(metadata);\n        }\n    });\n\n}\nproducer.close();\n```\n\n## 配置\n\n- acks\n  - 定了必须要有多少个分区副本收到消息，生产者才会认为消息写入是成功的 \n  - acks=0 ，生产者在成功写入消息之前不会等待任何来自服务器的响应 当 broker 故障时有可能 丢失数据\n  - acks=1 ，只要集群的首领节点收到消息，生产者就会收到一个来自服务器的成功响应 如果在 follower同步成功之前 leader 故障，那么将会丢失数据\n  -  acks=all ，只有当所有参与复制的节点全部收到消息时，生产者才会收到一个来自服务器的成功响应 如果在 follower 同步完成后，broker 发送 ack 之前，leader 发生故障，那么会造成 数据重复\n- buffer.memory\n  - 设置生产者内存缓冲区的大小\n- compression.type\n   - 设置消息压缩算法\n- retries\n  - 决定了生产者可以重发消息的次数，如果达到这个次数，生产者会放弃重试并返回错误\n- batch.size\n  - 指定了一个批次可以使用的内存大小\n- linger.ms\n  -  KafkaProducer 会在批次填满或 linger.ms 达到上限时把批次发送出去。默认情况下，只要有可用的线程，生产者就会把消息发送出去\n- client.id\n- max.in.flight.requests.per.connection\n  - 指定了生产者在收到服务器响应之前可以发送多少个消息\n-  timeout.ms、request.timeout.ms 和 metadata.fetch.timeout.ms\n-  max.block.ms\n   - 调用send时最长的阻塞时间\n - max.request.siz\n - receive.buffer.bytes 和 send.buffer.bytes\n   - 分别指定了 TCP socket 接收和发送数据包的缓冲区大小\n\n**顺序保证**\n\n- 将max.in.flight.requests.per.connection设置为1\n\n![屏幕截图 2020-08-24 085111](/assets/屏幕截图%202020-08-24%20085111.png)\n\n保证顺序的方法就是：\n\n1. 每个主题只分为一个区\n2. 每次发送的消息发送到同一个分区\n\n## 序列化器\n\n- 自定义序列化器：实现`Serializer`接口\n  - 不推荐使用\n- 其他序列化\n  - avro：一种将shcema嵌入在数据里的序列化方式\n\n## 分区策略\n\n分区的原因：\n\n- 方便扩展\n- 提高并发\n\n分区原则：\n\n- 指明 partition 的情况下，直接将指明的值直接作为 partiton 值\n- 没有指明 partition 值但有 key 的情况下，将 key 的 hash 值与 topic 的 partition数进行取余得到 partition 值\n- 否则就是随机取一个值 然后再这个值的基础上进行轮询\n\n自定义分区器：\n\n实现`Partitioner`接口\n\n## 数据可靠性保证\n\n- Exactly Once\n\n将服务器的 ACK 级别设置为-1，可以保证 Producer 到 Server 之间不会丢失数据，即 AtLeast Once 语义\n\nAt Least Once + 幂等性 = Exactly Once\n","commitList":[{"date":"2021-10-08T12:45:10+08:00","author":"cjiping","message":"doc开发期 构建期调整","hash":"704efe7455b7fb2fbd81ec60099191ff982e639a"},{"date":"2021-10-07T19:38:58+08:00","author":"My","message":"init","hash":"4e0456332231ba0523aa526415f9982377358870"}],"hasMoreCommit":false,"totalCommits":0}