{"content":"# kafka\n\nKafka 是一个分布式的基于发布/订阅模式的消息队列（Message Queue），主要应用于大数据实时处理领域\n\n## 特点\n\n- 多生产者 多消费者\n- 基于磁盘的数据存储\n- 伸缩性\n  -  broker可以不断扩展\n- 高性能\n\n## 基础概念\n\n消息和批次\n  - 消息是kafka的数据单元\n  - 批次是一组消息\n\n模式\n  - schema 使用额外的结构定义消息内容\n\n主题和分区\n  - 消息通过主题分类\n  - 主题被分为若干个分区 通过分区来实现数据冗余和伸缩性\n\n![屏幕截图 2020-08-12 152257](/assets/屏幕截图%202020-08-12%20152257.png)\n\n生产者和消费者\n  - 生产者创建消息\n  - 消费者读取消息 一个分区只能由一个组内消费者消费 通过偏移量记录消息消费位置\n\n![屏幕截图 2020-08-12 152638](/assets/屏幕截图%202020-08-12%20152638.png)\n\nbroker 和集群\n  - broker 独立的 kafka 服务器\n  - 每个集群都有一个broker 充当集群控制器\n\n![屏幕截图 2020-08-12 152955](/assets/屏幕截图%202020-08-12%20152955.png)\n\n对于消息 kafka会保留一段时间或者达到一定大小的字节数 旧的消息会被删除\n\n多集群\n\n![屏幕截图 2020-08-12 153137](/assets/屏幕截图%202020-08-12%20153137.png)\n\n## 使用场景\n\n- 活动跟踪\n  - 生产者产生事件 消费者读取事件进行统计\n- 传递消息\n- 度量指标 日志记录\n  - 收集系统度量指标和日志\n- 日志系统\n- 流处理\n\n## 架构\n\n![屏幕截图 2020-08-03 133557](/assets/屏幕截图%202020-08-03%20133557.png)\n\n- Partition ：为了实现扩展性，一个非常大的 topic 可以分布到多个 broker（即服务器）上，\n一个 topic  可以分为多个 partition，每个 partition 是一个有序的队列；\n- Replica： ：副本，为保证集群中的某个节点发生故障时，该节点上的 partition 数据不丢失，且 kafka 仍然能够继续工作，kafka 提供了副本机制，一个 topic 的每个分区都有若干个副本，\n一个 leader 和若干个 follower。\n- leader ：每个分区多个副本的“主”，生产者发送数据的对象，以及消费者消费数据的对\n象都是 leader。\n  - 生产者和消费者只与 leader 副本交互,当 leader 副本发生故障时会从 follower 中选举出一个 leader,但是 follower 中如果有和 leader 同步程度达不到要求的参加不了 leader 的竞选\n- follower ：每个分区多个副本中的“从”，实时从 leader 中同步数据，保持和 leader 数据\n的同步。leader 发生故障时，某个 follower 会成为新的 follower。\n\n### 分区与副本机制\n\n- 各个 Partition 可以分布在不同的 Broker 上, 这样便能提供比较好的并发能力（负载均衡）\n- 副本极大地提高了消息存储的安全性, 提高了容灾能力，不过也相应的增加了所需要的存储空间\n\n### zk的作用\n\n主要为 Kafka 提供元数据的管理的功能\n\n- Broker 注册 ：在 Zookeeper 上会有一个专门用来进行 Broker 服务器列表记录的节点\n- Topic 注册：分区信息及与 Broker 的对应关系也都是由 Zookeeper 在维护\n\n## 应用场景\n\n- 消息队列\n- 行为跟踪\n- 日志收集\n- 流处理\n- 事件源\n- 持久性日志\n\n## 搭建\n\n- 安装java zookeeper\n- 下载二进制包\n- `./kafka-server-start.sh`\n\n## 配置\n\nbroker 配置\n\n- broker.id\n  - 在集群中唯一\n  - 需要多少个broker\n    - 需要多少磁盘空间保留数据\n    - 集群处理请求的能力\n- port\n- zookeeper.connect\n- log.dirs\n  - 消息保存在磁盘上的位置\n- num.recovery.threads.per.data.dir\n  - 使用指定的线程池来处理日志\n- auto.create.topics.enable\n  - 自动创建主题\n    - 当一个生产者开始往主题写入消息时\n    - 当一个消费者开始读取\n    - 客户端向主题发送元数据请求\n\n主题配置\n\n- num.partitions\n  - 默认分区数量\n- log.retention.ms\n  - 数据保留多久\n- log.retention.bytes\n  - 主题保留的数据大小\n- log.segment.bytes\n  - 一个日志片段的最大大小\n- log.segment.ms\n  - 日志片段的最长打开时间\n- message.max.bytes\n  - 消息最大大小\n\n## 命令操作\n\n- 列出topic\n\n```sh\n./kafka-topics.sh --list --zookeeper 172.17.0.1:2181\n```\n\n- 创建topic\n\n```sh\n/opt/kafka/bin/kafka-topics.sh --create --zookeeper 172.17.0.1:2181 --replication-factor 1 --partitions 2 --topic my_log\n```\n\n- 生产者\n\n```sh\n./kafka-console-producer.sh --topic first --broker-list 172.17.0.1:9092\n```\n\n- 消费者\n\n```sh\n./kafka-console-consumer.sh --topic first --bootstrap-server 172.17.0.1:9092\n```\n\n## 工作流程\n\n![屏幕截图 2020-08-05 153846](/assets/屏幕截图%202020-08-05%20153846.png)\n\nKafka 中消息是以 topic 进行分类的，生产者生产消息，消费者消费消息，都是面向 topic的\n\n每个 partition 对应于一个 log 文件，该 log 文件中存储的就是 producer 生产的数据\n\nProducer 生产的数据会被不断追加到该log 文件末端，且每条数据都有自己的 offset。消费者组中的每个消费者，都会实时记录自己消费到了哪个 offset，以便出错恢复时，从上次的位置继续消费\n\n![屏幕截图 2020-08-05 155131](/assets/屏幕截图%202020-08-05%20155131.png)\n\nindex与log文件的作用：\n\n![屏幕截图 2020-08-05 155619](/assets/屏幕截图%202020-08-05%20155619.png)\n\n## 深入\n\n### 集群成员关系\n\nbroker通过创建临时节点把自己的 ID 注册到 Zookeeper\n\n控制器：一个特殊的broker 通过在zk创建临时节点进行选举\n\n控制器负责在节点加入或离开集群时进行分区首领选举。控制器使用epoch 来避免“脑裂”\n\n### 复制\n\n- 首领副本\n  - 所有生产者请求和消费者请求都会经过这个副本\n- 跟随者副本\n  - 从首领那里复制消息，保持与首领一致的状态\n\n### 请求处理\n\n![屏幕截图 2020-08-21 143247](/assets/屏幕截图%202020-08-21%20143247.png)\n\n生产请求：\n\n在消息被写入分区的首领之后，broker 开始检查 acks 配置参数——如果 acks 被设为 0 或 1 ，那么 broker 立即返回响应；如果 acks 被设为 all ，那么请求会被保存在一个叫作炼狱的缓冲区里，直到首领发现所有跟随者副本都复制了消息，响应才会被返回给客户端\n\n获取请求：\n\nbroker 将按照客户端指定的数量上限从分区里读取消息，再把消息返回给客户端。Kafka 使用零复制技术向客户端发送消息(直接从文件系统缓存复制到网卡)\n\n![屏幕截图 2020-08-21 144218](/assets/屏幕截图%202020-08-21%20144218.png)\n\n所有同步副本复制了这些消息，才允许消费者读取它们\n\n![屏幕截图 2020-08-21 144435](/assets/屏幕截图%202020-08-21%20144435.png)\n\n### 物理存储\n\n文件管理：\n\n分区分成若干个片段 当前正在写入数据的片段叫作活跃片段\n\n## 可靠数据传递\n\nkafka 的保证：\n\n- 分区消息的顺序\n- 只有当消息被写入分区的所有同步副本时（但不一定要写入磁盘），它才被认为是“已提交”的\n- 只要还有一个副本是活跃的，那么已经提交的消息就不会丢失\n- 消费者只能读取已提交的消息\n\n副本的同步保证：\n\n- 与 Zookeeper 之间有一个活跃的会话，也就是说，它在过去的 6s（可配置）内向Zookeeper 发送过心跳\n- 过去的 10s 内（可配置）从首领那里获取过消息\n- 过去的 10s 内从首领那里获取过最新的消息\n\n### broker\n\n复制系数：\n\n主题级别 replication.factor broker级别  default.replication.factor\n\n如果复制系数为 N，那么在 N-1 个 broker 失效的情况下，仍然能够从主题读取数据或向主题写入数据，同时 它们也会占用N倍的磁盘空间、\n\n不完全首领选举：\n\n如果把 unclean.leader.election.enable 设为 true ，就是允许不同步的副本成为首领 就要承担丢失数据和出现数据不一致的风险\n\n最少同步副本：\n\nmin.insync.replicas 如果要确保已提交的数据被写入不止一个副本，就需要把最少同步副本数量设置为大一点\n\n### 生产者\n\n发送确认：\n\nacks：0  能够通过网络把消息发送出去，那么就认为消息已成功写入\n\n1 ：意味着首领在收到消息并把它写入到分区数据文件（不一定同步到磁盘上）时\n会返回确认或错误响应\n\nall： 首领在返回确认或错误响应之前，会等待所有同步副本都收到消息\n\n重试参数：\n\n对于一些错误 可以通过重试来解决 如： LEADER_NOT_AVAILABLE\n\n### 消费者\n\n显示提交偏移量：\n\n- 处理完事件再提交\n- 批量提交\n- 重试\n- 维护状态\n- 避免对消息处理时间过程 否则会造成无法及时发送心跳\n- 仅一次传递\n  - 暂时支持不了 使用幂等性写入来实现\n\n## 数据管道\n\n需要考虑的问题：\n\n- 及时性\n- 可靠性\n  - 至少一次传递 仅一次传递\n- 吞吐量要求\n  - 高\n  - 动态调整\n- 数据格式与转换问题\n- 安全性\n  - 传输安全\n  - 权限安全\n- 故障处理\n- 数据管道与上下游的耦合\n\n### Connect\n\n启动 connect:\n\n```sh\n./bin/connect-distributed.sh ./config/connect-distributed.properties\n```\n\n文件数据源:\n\n```\nPOST localhost:8083/connectors\n{\"name\":\"load-kafka-config\", \"config\":{\"connector.class\":\"FileStreamSource\",\"file\":\"config/server.properties\",\"topic\":\"kafka-config-topic\"}}\n```\n\n传递文件数据源到主题上\n\n**深入**\n\n- 连接器\n- 任务\n- worker进程\n- 转换器\n- 偏移量管理\n\n## 集群镜像\n\n使用场景：\n\n- 区域集群 中心集群\n- 数据冗余\n- 云迁移\n\n### 多集群架构\n\n跨数据中心通信：\n\n- 高延迟\n- 带宽有限\n- 高成本\n\n中心架构：\n\n![屏幕截图 2020-08-22 144033](/assets/屏幕截图%202020-08-22%20144033.png)\n\n主从架构：\n\n![屏幕截图 2020-08-22 144112](/assets/屏幕截图%202020-08-22%20144112.png)\n\n双活架构：\n\n![屏幕截图 2020-08-22 144741](/assets/屏幕截图%202020-08-22%20144741.png)\n\n主备架构：\n\n![屏幕截图 2020-08-22 145035](/assets/屏幕截图%202020-08-22%20145035.png)\n\n### MirrorMaker\n\n![屏幕截图 2020-08-22 145553](/assets/屏幕截图%202020-08-22%20145553.png)\n\n如果有可能，尽量让 MirrorMaker 运行在目标数据中心里\n\n## 监控\n\n所有度量指标都可以通过 Java Management Extensions（JMX）接口来访问\n\n### broker\n\n非同步分区数量：\n\n- 如果集群里多个 broker 的非同步分区数量一直保持不变，那说明集群中的某个 broker 已经离线了\n- 如果非同步分区的数量是波动的，或者虽然数量稳定但并没有 broker 离线，说明集群出现了性能问题\n\n集群问题：\n\n- 不均衡的负载\n- 资源过度消耗\n\n主机问题：\n\n- 硬件\n- 进程冲突\n- 配置问题\n\n## 流式处理\n\n> 数据流:无边界数据集的抽象表示\n> 数据流是有序的, 不可变的, 可重播的\n> 流式处理是持续地从一个无边界的数据集读取数据，然后对它们进行处理并生成结果\n\n### 概念\n\n时间：\n\n- 事件时间\n  -  所追踪事件的发生时间和记录的创建时间\n- 处理时间\n  - 收到事件之后要对其进行处理的时间\n\n状态：\n\n- 内部状态\n  -  只能被单个应用程序实例访问\n- 外部状态\n  - 使用外部的数据存储来维护\n\n时间窗口：\n\n![屏幕截图 2020-08-23 112304](/assets/屏幕截图%202020-08-23%20112304.png)\n\n### 设计模式\n\n单事件处理：\n\n![屏幕截图 2020-08-23 112459](/assets/屏幕截图%202020-08-23%20112459.png)\n\n本地状态事件处理：\n\n![屏幕截图 2020-08-23 112551](/assets/屏幕截图%202020-08-23%20112551.png)\n\n多阶段处理：\n\n![屏幕截图 2020-08-23 112748](/assets/屏幕截图%202020-08-23%20112748.png)\n\n外部数据源填充：\n\n![屏幕截图 2020-08-23 112929](/assets/屏幕截图%202020-08-23%20112929.png)\n\n连接流：\n\n![屏幕截图 2020-08-23 113209](/assets/屏幕截图%202020-08-23%20113209.png)\n\n对乱序事件重排序\n\n重新处理：\n\n使用新处理程序从头读取数据流生成结果流\n\n### Kafka Streams 架构\n\n拓扑结构：\n\n![屏幕截图 2020-08-23 114308](/assets/屏幕截图%202020-08-23%20114308.png)\n\n对拓扑结构伸缩：\n\n![屏幕截图 2020-08-23 114438](/assets/屏幕截图%202020-08-23%20114438.png)","commitList":[{"date":"2021-10-08T12:45:10+08:00","author":"cjiping","message":"doc开发期 构建期调整","hash":"704efe7455b7fb2fbd81ec60099191ff982e639a"},{"date":"2021-10-07T19:38:58+08:00","author":"My","message":"init","hash":"4e0456332231ba0523aa526415f9982377358870"}],"hasMoreCommit":false,"totalCommits":0}