{"content":"# 消费者\n\n![屏幕截图 2020-08-21 133318](/assets/屏幕截图%202020-08-21%20133318.png)\n\n分区的所有权从一个消费者转移到另一个消费者，这样的行为被称为再均衡\n\n消费者通过向被指派为群组协调器的 broker（不同的群组可以有不同的协调器）发送心跳来维持它们和群组的从属关系以及它们对分区的所有权关系\n\n```java\nProperties props = new Properties();\n//kafka 集群，broker-list\nprops.put(\"bootstrap.servers\", \"172.24.211.140:9092\");\nprops.put(\"group.id\", \"consumer1\");\nprops.put(\"key.deserializer\",\n        \"org.apache.kafka.common.serialization.StringDeserializer\");\nprops.put(\"value.deserializer\",\n        \"org.apache.kafka.common.serialization.StringDeserializer\");\nKafkaConsumer<String, String> consumer = new KafkaConsumer<String,\n                        String>(props);\nconsumer.subscribe(List.of(\"test\"));\nwhile(true){\n    ConsumerRecords<String, String> records = consumer.poll(Duration.ofMillis(1000));\n    for (ConsumerRecord<String, String> record : records) {\n        System.err.println(record);\n    }\n}\n```\n\n消费方式:\n\n采用 pull（拉）模式从 broker 中读取数据\n\n相较于服务器 push 模式，pull模式使消费者可以根据自己的情况来决定消费的速率，另一方面，pull模式每次也可以批量拉取数据，提高服务器吞吐量，而pull模式一旦有消息产生，就会立马推送，这意味着网络开销会比pull模式高一些。\n\n但pull模式也有一些缺陷，如果没有消息的话，客户端就会在那里空转等待，所以Kafka为消费者的poll方法指定了一个时间参数，避免空转浪费CPU资源\n\n## 配置\n\n- fetch.min.bytes\n  - 指定了消费者从服务器获取记录的最小字节数\n- fetch.max.wait.ms\n  - 指定 broker 的等待时间\n- max.partition.fetch.bytes\n   - 指定了服务器从每个分区里返回给消费者的最大字节数\n- session.timeout.ms\n  - 指定了消费者在被认为死亡之前可以与服务器断开连接的时间\n- auto.offset.reset\n  - 指定了消费者在读取一个没有偏移量的分区或者偏移量无效的情况下（因消费者长时间失效，包含偏移量的记录已经过时并被删除）该作何处理\n  - earliest 当分区下有已提交的offset时，从提交的offset开始消费；无提交的offset时，从头开始消费\n  - latest 当分区下有已提交的offset时，从提交的offset开始消费；无提交的offset时，消费新产生的该分区下的数据\n  - none 当该topic下所有分区中存在未提交的offset时，抛出异常\n- enable.auto.commit\n  - 指定了消费者是否自动提交偏移量\n- partition.assignment.strategy 决定哪些分区应该被分配给哪个消费者\n  - range:该策略会把主题的若干个连续的分区分配给消费者\n  - 轮询：该策略把主题的所有分区逐个分配给消费者\n- client.id\n- max.poll.records 控制单次调用 call() 方法能够返回的记录数量\n-  receive.buffer.bytes 和 send.buffer.bytes\n   -  读写数据时用到的 TCP 缓冲区也可以设置大小\n\n## 偏移量\n\n每一个消费者组都会对有进行消费的主题分区的偏移量进行记录，这也就意味着消费者可以手动设置这个偏移量从头消费数据。\n\n更新分区当前偏移量的操作叫作**提交**\n\nKafka 0.9 版本之前，consumer 默认将 offset 保存在 Zookeeper 中，从 0.9 版本开始，consumer 默认将 offset 保存在 Kafka 一个内置的 topic 中，该 topic为__consumer_offsets。\n\n**自动提交：**\n\n- 如果 enable.auto.commit 被设为 true ，那么每过 5s，消费者会自动把从 poll() 方法接收到的最大偏移量提交上去\n\n**手动提交：**\n\n把 auto.commit.offset 设为 false ，使用 commitSync()\n\n异步提交 commitAsync() , 但该方法在发生错误时不会进行重试\n\n**再均衡监听：**\n\n订阅的时候传入 ConsumerRebalanceListener 实现相关接口\n\n**从特定偏移量开始处理：**`seekToBeginning(..)`\n\n**读取特定偏移量：**`seek(..)`\n\n## 退出\n\n其他线程调用`consumer.wakeup()` 会使consumer在poll抛出异常 然后进行close即可\n\n## 没有群组的消费者\n\n调用assign为其设置消费的分区\n","commitList":[{"date":"2021-10-08T12:45:10+08:00","author":"cjiping","message":"doc开发期 构建期调整","hash":"704efe7455b7fb2fbd81ec60099191ff982e639a"},{"date":"2021-10-07T19:38:58+08:00","author":"My","message":"init","hash":"4e0456332231ba0523aa526415f9982377358870"}],"hasMoreCommit":false,"totalCommits":0}