{"content":"# ElasticSearch\n\n> ElasticSearch是一个基于Lucene的搜索服务器。它提供了一个分布式多用户能力的全文搜索引擎，基于RESTful web接口\n\n- Near Realtime\n  - 从写入数据到数据可以被搜索到有一个小延迟，大概是 1s\n  - 基于 es 执行搜索和分析可以达到秒级\n\n## 优势\n\n- 横向可扩展\n- 分片机制提供更好的分布性\n- 高可用\n\n## 安装\n\n> 使用 docker\n\n```shell\ndocker run elasticsearch:7.3.1\n```\n\n```shell\ndocker network create somenetwork;\ndocker run -d --name elasticsearch --net somenetwork -p 9200:9200 -p 9300:9300 -e \"discovery.type=single-node\" elasticsearch:7.3.1\n```\n\n9300端口： ES节点之间通讯使用\n9200端口： ES节点 和 外部 通讯使用\n\n## 图形化管理界面\n\n- [head](https://github.com/mobz/elasticsearch-head)\n\n## 概念\n\n- 集群(cluster)\n  - 多个节点组成\n- 节点(node)\n  - 服务器实例\n- 索引（index）\n  - Databases 数据库\n- ​类型（type）\n  - Table 数据表\n- ​文档（Document）\n  - Row 行\n- ​字段（Field）\n  - Columns 列\n- shard\n  - es 可以将一个索引中的数据切分为多个 shard，分布在多台服务器上存储\n- replica\n  - 任何一个服务器随时可能故障或宕机，此时 shard 可能就会丢失，因此可以为每个 shard 创建多个replica 副本。replica 可以在 shard 故障时提供备用服务，所以同一片shard跟replica不能存放在同一节点\n\n![批注 2020-03-19 081056](/assets/批注%202020-03-19%20081056.png)\n\n- 映射 mapping\n\n## 索引结构\n\n![批注 2019-10-18 145410](/assets/批注%202019-10-18%20145410.png)\n\n- 倒排索引：根据词找文章\n\nDocId | Doc\n----- | -------------------------------\n1     | 谷歌地图之父跳槽 Facebook\n2     | 谷歌地图之父加盟 Facebook\n3     | 谷歌地图创始人拉斯离开谷歌加盟 Facebook\n4     | 谷歌地图之父跳槽 Facebook 与 Wave 项目取消有关\n5     | 谷歌地图之父拉斯加盟社交网站 Facebook\n\n对这些doc进行分词之后，以词为主键，记录哪些doc出现了这些词\n\nWordId | Word     | DocIds\n------ | -------- | ---------\n1      | 谷歌       | 1,2,3,4,5\n2      | 地图       | 1,2,3,4,5\n3      | 之父       | 1,2,4,5\n4      | 跳槽       | 1,4\n5      | Facebook | 1,2,3,4,5\n6      | 加盟       | 2,3,5\n7      | 创始人      | 3\n8      | 拉斯       | 3,5\n9      | 离开       | 3\n10     | 与        | 4\n..     | ..       | ..\n\n- 正排索引：根据文章找词\n\n## 操作\n\n### 创建索引\n\n```json\nPUT /blog\n{\n    \"settings\": {\n        \"number_of_shards\": 3,\n        \"number_of_replicas\": 2\n      }\n}\n```\n\n- 获取索引库信息\n\n`GET /blog`\n\n- 删除索引库\n\n`DELETE /blog`\n\n### 添加映射\n\n```json\nPUT /索引库名/_mapping/类型名称\n{\n  \"properties\": {\n    \"字段名\": {\n      \"type\": \"类型\",\n      \"index\": true,\n      \"store\": true,\n      \"analyzer\": \"分词器\"\n    }\n  }\n}\n```\n\n**数据类型**\n\ntext：该类型被用来索引长文本，在创建索引前会将这些文本进行分词，转化为词的组合，建立索引；允许es来检索这些词，text类型不能用来排序和聚合。\nkeyword：该类型不需要进行分词，可以被用来检索过滤、排序和聚合，keyword类型自读那只能用本身来进行检索（不可用text分词后的模糊检索）\n数值型：long、integer、short、byte、double、float\n日期型：date\n布尔型：boolean\n二进制型：binary\n\n- 查看映射关系\n\n`GET /索引库名/_mapping`\n\n- 更新索引\n\n`POST http://my-pc:9200/blog/{indexName}`\n\n### 添加文档\n\n```json\nPOST /索引库名/类型名\n{\n    \"key\":\"value\"\n}\n```\n\n- 自定义id\n\n```json\nPOST /索引库名/类型/id值\n{...}\n```\n\n### 删除文档\n\n`DELETE http://my-pc:9200/blog/hello/1`\n\n### 修改文档\n\n`UPDATE http://my-pc:9200/blog/hello/1`\n\n### 查询\n\n#### 基本查询\n\n```json\nGET /索引库名/_search\n{\n    \"query\":{\n        \"查询类型\":{\n            \"查询条件\":\"查询条件值\"\n        }\n    }\n}\n```\n\n- 根据ID查询\n\n`GET http://my-pc:9200/blog/hello/1`\n\n- 根据字段查询\n\n>Term Query为精确查询，在搜索时会整体匹配关键字，不再将关键字分词。 \n\n```json\nGET /shop/_search\n{\n  \"_source\": [\"title\",\"price\"],\n  \"query\": {\n    \"term\": {\n      \"price\": 2699\n    }\n  }\n}\n```\n\n- queryString查询\n\n```json\n{\n    \"query\":{\n        \"query_string\":{\n            \"default_field\":\"content\",\n            \"query\":\"内容\"\n        }\n    }\n}\n```\n\n**过滤**\n\n- includes：来指定想要显示的字段\n- excludes：来指定不想要显示的字段\n\n```json\nGET /shop/_search\n{\n  \"_source\": {\n    \"includes\":[\"title\",\"price\"]\n  },\n  \"query\": {\n    \"term\": {\n      \"price\": 2699\n    }\n  }\n}\n```\n\n**排序**\n\n```json\nGET /shop/_search\n{\n  ...\n  \"sort\": [\n    {\n      \"price\": {\n        \"order\": \"desc\"\n      }\n    }\n  ]\n}\n```\n\n**模糊查询**\n\n```json\nGET /heima/_search\n{\n  \"query\": {\n    \"fuzzy\": {\n        \"title\": {\n            \"value\":\"appla\",\n            \"fuzziness\":1\n        }\n    }\n  }\n}\n```\n\n## 分词\n\n### 内置的分词器\n\n- Standard Analyzer\n- Simple Analyzer\n- Whitespace Analyzer\n- Stop Analyzer\n- Keyword Analyzer\n- Pattern Analyzer\n- Language Analyzers\n- Fingerprint Analyzer\n\n### 测试分词\n\n`GET /_analyze`\n\n```json\n{\n  \"analyzer\": \"standard\",\n  \"text\": \"中文测试分词\"\n}\n```\n\n### 中文分词器\n\n[下载](https://github.com/medcl/elasticsearch-analysis-ik)\n\n```shell\ndocker run --name elasticsearch --net somenetwork -v /root/plugin:/usr/share/elasticsearch/plugins -p 9200:9200 -p 9300:9300 -e \"discovery.type=single-node\" elasticsearch:7.3.1\n```\n\n`GET http://my-pc:9200/_analyze`\n\n```json\n{\n  \"analyzer\": \"ik_max_word\",\n  \"text\": \"中文测试分词\"\n}\n```\n\nik 的两种模式：\n\n- max：会将文本做最细粒度的拆分 会穷尽所有的可能\n- smart：最最粗粒度的划分\n\n## 聚合\n\n>桶\n\n## ES集群\n\n采用ES集群，将单个索引的分片到多个不同分布式物理机器上存储，从而可以实现高可用、容错性\n\n### 架构\n\nes 集群多个节点，会自动选举一个节点为 master 节点\nmaster 节点宕机了，那么会重新选举一个节点为 master 节点\n\n非 master节点宕机了，那么会由 master 节点，让那个宕机节点上的 primary shard 的身份转移到其他机器上的 replica shard\n\n![批注 2020-03-19 081559](/assets/批注%202020-03-19%20081559.png)\n\n可以使用三个节点，将索引分成三份，每个节点存放一份primary shard，两份replica，这样就算只剩下一台节点，也能保证服务可用\n\n### 搭建\n\n- 配置\n\n```yml\n# 集群名称，必须保持一致\ncluster.name:  elasticsearch\n# 节点的名称\nnode.name: node-1\n# 监听网段\nnetwork.host: 0.0.0.0\n# 本节点rest服务端口\nhttp.port: 9201\n# 本节点数据传输端口\ntransport.tcp.port: 9301\n# 集群节点信息\ndiscovery.seed_hosts: [\"127.0.0.1:9301\",\"127.0.0.1:9302\",\"127.0.0.1:9303\"]\ncluster.initial_master_nodes: [\"node-1\",\"node-2\",\"node-3\"]\n```\n\n另外两个节点配置省略...\n\n# JAVA客户端\n\n- 依赖\n\n```xml\n<dependency>\n    <groupId>org.elasticsearch</groupId>\n    <artifactId>elasticsearch</artifactId>\n    <version>7.3.1</version>\n</dependency>\n\n<dependency>\n    <groupId>org.elasticsearch.client</groupId>\n    <artifactId>transport</artifactId>\n    <version>7.3.1</version>\n</dependency>\n```\n\n- 连接\n\n```java\nSettings settings = Settings.builder()\n                .put(\"cluster.name\",\"docker-cluster\")\n                .build();\n\nTransportClient client = new PreBuiltTransportClient(settings);\nclient.addTransportAddress(\n            new TransportAddress(InetAddress.getByName(\"my-pc\"),9300));\n```\n\n- 创建索引\n\n```java\nclient.admin().indices().prepareCreate(\"index\").get();\n```\n\n- 设置映射\n\n```java\nXContentBuilder builder = XContentFactory.jsonBuilder()\n                .startObject()\n                .startObject(\"article\")\n                .startObject(\"properties\")\n                .startObject(\"id\")\n                .field(\"type\", \"long\")\n                .field(\"store\", true)\n                .endObject()\n                .startObject(\"title\")\n                .field(\"type\", \"text\")\n                .field(\"store\", true)\n                .field(\"analyzer\", \"ik_smart\")\n                .endObject()\n                .startObject(\"content\")\n                .field(\"type\", \"text\")\n                .field(\"store\", true)\n                .field(\"analyzer\", \"ik_smart\")\n                .endObject()\n                .endObject()\n                .endObject()\n                .endObject();\n  client.admin().indices().preparePutMapping(\"index\")\n          .setType(\"article\")\n          .setSource(builder)\n          .get();\n```\n\n- 添加文档\n\n```java\nXContentBuilder builder = XContentFactory.jsonBuilder()\n                .startObject()\n                    .field(\"id\",1L)\n                    .field(\"title\",\"央视快评：勇做敢于斗争善于斗争的战士\")\n                    .field(\"content\",\"9月3日，习近平总书记在中央党校（国家行政学院）中青年干部培训班开班式上发表重要讲话强调，广大干部特别是年轻干部要经受严格的思想淬炼、政治历练、实践锻炼，发扬斗争精神，增强斗争本领，为实现“两个一百年”奋斗目标、实现中华民族伟大复兴的中国梦而顽强奋斗。\")\n                .endObject();\nclient.prepareIndex(\"index\",\"article\",\"1\")\n        .setSource(builder)\n        .get();\n```\n\n- POJO添加文档\n\n```java\nArticle article = new Article();\n        article.setId(3L);\n        article.setTitle(\"3央视快评：勇做敢于斗争善于斗争的战士\");\n        article.setContent(\"9月3日3333，（国家行政学院）中青年干部培训班开班式上发表重要讲话强调，广大干部特别是年\");\n        String json = new ObjectMapper().writeValueAsString(article);\n\nclient.prepareIndex(\"index\",\"article\",\"3\")\n        .setSource(json, XContentType.JSON)\n        .get();\n```\n\n## 查询\n\n- 根据ID\n\n```java\nQueryBuilder queryBuilder = QueryBuilders.idsQuery().addIds(\"1\",\"2\");\nSearchResponse response = client.prepareSearch(\"index\")\n        .setTypes(\"article\")\n        .setQuery(queryBuilder)\n        .get();\nSearchHits hits = response.getHits();\n\nSystem.out.println(\"总记录:\"+hits);\nSearchHit[] ret = hits.getHits();\n\nfor (SearchHit documentFields : ret) {\n    Map<String, Object> map = documentFields.getSourceAsMap();\n    System.out.println(\"id:\"+map.get(\"id\"));\n    System.out.println(\"title:\"+map.get(\"title\"));\n    System.out.println(\"content:\"+map.get(\"content\"));\n    System.out.println(\"-------------------\");\n}\n```\n\n- 根据term\n\n```java\nQueryBuilder queryBuilder = QueryBuilders.termQuery(\"title\",\"斗争\");\n```\n\n- 根据queryString\n\n```java\nQueryBuilder queryBuilder = QueryBuilders.queryStringQuery(\"青年强调\")\n                .defaultField(\"content\");\n```\n\n- 分页查询\n\n```java\nSearchResponse response = client.prepareSearch(\"index\")\n                .setTypes(\"article\")\n                .setQuery(queryBuilder)\n                .setFrom(10)\n                .setSize(5)\n                .get();\n```\n\n- 高亮显示结果\n\n```java\nHighlightBuilder highlightBuilder = new HighlightBuilder();\nhighlightBuilder.field(highlight);\nhighlightBuilder.preTags(\"<em>\");\nhighlightBuilder.postTags(\"</em>\");\n\nSearchResponse response = client.prepareSearch(\"index\")\n        .setTypes(\"article\")\n        .setQuery(queryBuilder)\n        .highlighter(highlightBuilder)\n        .get();\nSearchHits hits = response.getHits();\n\nSystem.out.println(\"总记录:\"+hits.getTotalHits());\nSearchHit[] ret = hits.getHits();\n\nfor (SearchHit documentFields : ret) {\n    Map<String, Object> map = documentFields.getSourceAsMap();\n\n    System.out.println(\"id:\"+map.get(\"id\"));\n    System.out.println(\"content:\"+map.get(\"content\"));\n    Map<String, HighlightField> highlightFields = documentFields.getHighlightFields();\n    System.out.println(highlightFields.get(highlight).getFragments()[0]);\n    System.out.println(\"-------------------\");\n\n}\n```\n\n## es操作过程\n\n### 写过程\n\n客户端选择一个协调节点（coordinating node）发送请求，协调节点将请求转发给对应的node\n对应的node在primary shard上处理请求，并同步到replica shard上\n\n![批注 2020-03-19 082208](/assets/批注%202020-03-19%20082208.png)\n\n#### 写过程原理\n\n![批注 2020-03-19 083304](/assets/批注%202020-03-19%20083304.png)\n\n数据先写入内存 buffer，然后每隔 1s，将数据 refresh 到 os cache，到了 os cache 数据就能被搜索到\n\n每隔 5s，将数据写入 translog 文件（这样如果机器宕机，内存数据全没，最多会有 5s 的数据丢失），translog 大到一定程度，或者默认每隔 30mins，会触发 commit 操作，将缓冲区的数据都 flush 到 segment file 磁盘文件中\n\n### 读过程\n\n客户端选择一个协调节点（coordinating node）发送根据ID查询请求，协调节点会根据id进行哈希，得到doc所在的分片，将请求转发到对应的node\n这个node然后会在primary shard与replica中使用随机轮询，进行负载均衡，返回document给协调节点\n协调节点再把document返回给客户端\n\n### 搜索过程\n\n客户端发送搜索请求给协调节点，协调节点将这个请求发送给所有的shard\n每个shard将自己的搜索结构返回给协调节点\n由协调节点进行数据的合并、排序、分页等操作，产出最终结果\n接着协调节点根据id再去查询对应的document的数据，返回给客户端\n\n### 删除/更新过程\n\n删除操作，会生成一个对应document id的.del文件，标识这个document被删除\n如果是更新操作，就是将原来的 doc 标识为 deleted 状态，然后新写入一条数据\n\n每refresh一次，会生成一个segment file，系统会定期合并这些文件，合并这些文件的时候，会物理删除标记.del的document\n\n## 性能优化\n\n### 杀手锏：filesystem cache\n\n![批注 2020-03-19 085001](/assets/批注%202020-03-19%20085001.png)\n\n在es中，doc的字段尽量只存储要被搜索的字段，这样可以节省内存，存放更多数据，做缓存效果更好\n\n### 数据预热\n\n对于一些热点数据，也要通过一些方式让它在缓存中\n\n### 冷热分离\n\n保证热点数据都在缓存里，提高系统性能\n\n### doc模型设计\n\n对于一些复杂的关联，最好在应用层面就做好，对于一些太复杂的操作，比如 join/nested/parent-child 搜索都要尽量避免，性能都很差的\n\n### 分页性能优化\n\n由于分页操作是由协调节点来完成的，所以翻页越深，性能越差\n解决：\n\n- 不允许深度翻页\n- 将翻页设计成不允许跳页，只能一页一页翻\n\n# kibana\n\nKibana是一个基于Node.js的Elasticsearch索引库数据统计工具，可以利用Elasticsearch的聚合功能，生成各种图表，如柱形图，线状图，饼图等。\n\n而且还提供了操作Elasticsearch索引数据的控制台，并且提供了一定的API提示，非常有利于我们学习Elasticsearch的语法。\n\n## 安装\n\n- docker\n\n```shell\ndocker pull kibana:5.6.8 # 拉取镜像\ndocker run -d --name kibana --net somenetwork -p 5601:5601 kibana:5.6.8 # 启动\n```\n","commitList":[{"date":"2021-10-08T12:45:10+08:00","author":"cjiping","message":"doc开发期 构建期调整","hash":"704efe7455b7fb2fbd81ec60099191ff982e639a"},{"date":"2021-10-07T19:38:58+08:00","author":"My","message":"init","hash":"4e0456332231ba0523aa526415f9982377358870"}],"hasMoreCommit":false,"totalCommits":0}