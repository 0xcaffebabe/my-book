{"content":"> 网络爬虫，是一种按照一定的规则，自动地抓取万维网信息的程序或者脚本。另外一些不常使用的名字还有蚂蚁、自动索引、模拟程序或者蠕虫。\n\n# HttpClient\n\n## Get请求\n\n```java\nHttpGet get = new HttpGet(\"http://www.baidu.com\");\n\n        try (CloseableHttpClient client = HttpClients.createDefault();\n             CloseableHttpResponse response = client.execute(get)) {\n            String s = EntityUtils.toString(response.getEntity(), \"utf8\");\n\n            System.out.println(s);\n        }\n```\n\n- 设置参数\n\n```java\nURIBuilder uriBuilder = new URIBuilder(\"http://www.baidu.com/s\").addParameter(\"wd\", \"关键词\");\nHttpGet get = new HttpGet(uriBuilder.build());\n```\n\n## POST请求\n\n```java\nvar request = new HttpPost(\"http://example\");\n        var pairs = List.of(new BasicNameValuePair(\"keys\", \"java\"), new BasicNameValuePair(\"keys\", \"python\"));\n        UrlEncodedFormEntity entity = new UrlEncodedFormEntity(pairs, \"utf8\");\n        request.setEntity(entity);\n```\n\n## 连接池\n\n```java\nPoolingHttpClientConnectionManager manager = new PoolingHttpClientConnectionManager();\n        // 最大连接数\n        manager.setMaxTotal(100);\n        // 每个主机最大连接数\n        manager.setDefaultMaxPerRoute(10);\n        CloseableHttpClient client = HttpClients.custom().setConnectionManager(manager).build();\n```\n\n## 请求参数\n\n```java\nRequestConfig config = RequestConfig.custom().setConnectTimeout(1000) // 获取连接的最长时间，单位ms\n                .setConnectionRequestTimeout(500) // 获取连接的最长时间\n                .setSocketTimeout(10000).build(); // 传输数据最长时间\n        HttpGet get = new HttpGet();\n        get.setConfig(config);\n```\n\n# Jsoup\n\n## DOM\n\n```java\nDocument doc = Jsoup.parse(new URL(\"http://www.baidu.com\"), 10000);\n        doc.getElementByXXX();\n```\n\n## 元素API\n\n```java\nElement e = doc.getElementById(\"login\");\n        System.out.println(e.id());\n        System.out.println(e.className());\n        System.out.println(e.classNames());\n        System.out.println(e.text());\n        System.out.println(e.attr(\"style\"));\n        System.out.println(e.attributes());\n```\n\n## 使用CSS选择器\n\n```java\ndoc.select(\"div\")\n                .forEach(System.out::println);\n```\n\n# WebMagic\n\n![](https://camo.githubusercontent.com/06cb8227231a6adf6d2a57b14b60a25389a25fe9/687474703a2f2f636f64653463726166742e6769746875622e696f2f696d616765732f706f7374732f7765626d616769632e706e67)\n\n## 使用\n\n- 实现PageProcessor\n\n```java\npublic class JobProcessor implements PageProcessor {\n\n    private Site site = Site.me().addHeader(\"User-Agent\",\"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/77.0.3865.90 Safari/537.36\");\n\n    @Override\n    public void process(Page page) {\n        page.putField(\"div1\",page.getHtml().css(\"#logo-2014\").get());\n        page.putField(\"div2\",page.getHtml().xpath(\"//div\").get());\n\n    }\n\n    @Override\n    public Site getSite() {\n        return site;\n    }\n}\n```\n\n- 运行\n\n```java\nSpider.create(new JobProcessor())\n                .addUrl(\"https://search.jd.com/Search?keyword=%E6%89%8B%E6%9C%BA&enc=utf-8&wq=%E6%89%8B%E6%9C%BA&pvid=9524dc8e0e2d45f08656f023fa60a0de\")\n                .run();\n```\n\n## 元素抽取\n\n- XPath\n- Regex\n- CSS\n\n```java\npage.putField(\"div1\",page.getHtml().css(\"#logo-2014\").get()); // 获取一条\n        page.putField(\"div2\",page.getHtml().xpath(\"//div[@id=logo-2014]\").all());  // 获取全部\n```\n\n## 获取链接\n\n```java\npage.getHtml().links()\n```\n\n- 递归访问\n\n```java\npage.addTargetRequests(page.getHtml().links().all());\n```\n\n## 输出数据\n\n- PipeLine\n\n```java\nSpider.create(new JobProcessor())\n                .addUrl(\"url\")\n                .addPipeline(new FilePipeline(\"./result.txt\"))\n                .run();\n```\n\n## Site\n\n## Scheduler\n\n- 使用布隆过滤器\n\n```java\nSpider.create(null)\n                .setScheduler(new QueueScheduler().setDuplicateRemover(new BloomFilterDuplicateRemover(100000)));\n```\n\n### 三种去重方式\n\n- HashSet\n- Redis\n- 布隆过滤器\n\n## [文档](http://webmagic.io/docs/zh/)\n\n# 爬虫分类\n\n- 通用\n- 聚焦\n- 增量式\n- 深层网络\n\n# 网页去重\n\n- simhash\n\n**海明距离**\n\n> 在信息编码中，两个合法代码对应位上编码不同的位数称为码距，又称海明距离。举例如下：10101和00110从第一位开始依次有第一位、第四、第五位不同，则海明距离为3\n\n# 使用代理\n\n```java\n        downloader.setProxyProvider(new SimpleProxyProvider(List.of(new Proxy(\"116.114.19.211\",443))));\n\n        Spider.create(new ProxyProcessor())\n                .addUrl(\"http://ip-api.com/json/?lang=zh-CN\")\n                .setDownloader(downloader)\n                .run();\n```\n\n\n","commitList":[{"date":"2021-10-08T12:45:10+08:00","author":"cjiping","message":"doc开发期 构建期调整","hash":"704efe7455b7fb2fbd81ec60099191ff982e639a"},{"date":"2021-10-07T19:38:58+08:00","author":"My","message":"init","hash":"4e0456332231ba0523aa526415f9982377358870"}],"hasMoreCommit":false,"totalCommits":0}